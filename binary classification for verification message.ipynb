{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             content  label\n",
      "0  NY&C ONLINE: $20 Puffer Vests Back Tonight! Al...  False\n",
      "1  MATCH ALERT: For the NEXT HOUR get an 800%-MAT...  False\n",
      "2  SMS passcodes: 1266502  2079684  3401452  4762...  False\n",
      "3  A new email has been received from notify@elea...  False\n",
      "4  af0603beaf848c829834343539393735306a4c2d74008d...  False\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.read_csv(\"training_data_full.csv\")\n",
    "dataset = dataframe.values\n",
    "print(dataframe.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate X, Y data\n",
    "X = dataset[:, 0]\n",
    "Y = dataset[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "print(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocessing(X):\n",
    "    documents = []\n",
    "    stemmer = WordNetLemmatizer()\n",
    "\n",
    "    for sen in range(0, len(X)):\n",
    "        # Remove all the special characters\n",
    "        document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "        # remove all single characters\n",
    "        document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "\n",
    "        # Remove single characters from the start\n",
    "        document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "\n",
    "        # Removing prefixed 'b'\n",
    "        document = re.sub(r'^b\\s+', '', document)\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        document = document.lower()\n",
    "\n",
    "        # Lemmatization\n",
    "        document = document.split()\n",
    "\n",
    "        document = [stemmer.lemmatize(word) for word in document]\n",
    "        document = ' '.join(document)\n",
    "\n",
    "        documents.append(document)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Generate TFIDF feature values with removing stopwords\n",
    "tfidfconverter = TfidfVectorizer(max_features=1000, stop_words=stopwords.words('english'))\n",
    "X = tfidfconverter.fit_transform(preprocessing(X)).toarray()\n",
    "# Dump the file\n",
    "pickle.dump(tfidfconverter, open(\"tfidfconverter.pkl\", \"wb\"))\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data size is 20 % of dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, encoded_Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create RF classifier\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "# fit to train the classifier\n",
    "classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict \n",
    "def predict(classifier, X_test):\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "# inverse transform\n",
    "def inverse_transform(encoder, y_pred):\n",
    "    label_pred = encoder.inverse_transform(y_pred)\n",
    "    return label_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6014   15]\n",
      " [   6 2965]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      6029\n",
      "           1       0.99      1.00      1.00      2971\n",
      "\n",
      "    accuracy                           1.00      9000\n",
      "   macro avg       1.00      1.00      1.00      9000\n",
      "weighted avg       1.00      1.00      1.00      9000\n",
      "\n",
      "0.9976666666666667\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "y_pred = predict(classifier, X_test)\n",
    "# display measurements\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model into a pickle file\n",
    "with open('binary_classifier.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(classifier,picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from a pickle file\n",
    "with open('binary_classifier.pkl', 'rb') as training_model:\n",
    "    classifier = pickle.load(training_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Predict the new unlabeled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 content  label\n",
      "0      NY&C ONLINE: $20 Puffer Vests Back Tonight! Al...    NaN\n",
      "1      Hi, thanks for visiting Core Physicians. Pleas...    NaN\n",
      "2      There is a new VET available from Sep 30, 2020...    NaN\n",
      "3      Pres. Trump has requested your input on nomina...    NaN\n",
      "4      NY&C ONLINE: $20 Puffer Vests Back Tonight! Al...    NaN\n",
      "...                                                  ...    ...\n",
      "9996   Thomas Podmajersky paid you $100.00 Payment fo...    NaN\n",
      "9997   9/28 from being an @Home Learner then we would...    NaN\n",
      "9998   Time is running out! Complete the 2020 Census ...    NaN\n",
      "9999   Pres. Trump has requested your input on nomina...    NaN\n",
      "10000  Pres. Trump has requested your input on nomina...    NaN\n",
      "\n",
      "[10001 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "test_dataframe = pd.read_csv(\"test_data_10000.csv\")\n",
    "print(test_dataframe)\n",
    "test_dataset = test_dataframe.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001\n"
     ]
    }
   ],
   "source": [
    "# Get X data and fit it with TF-IDF Vectorizer\n",
    "X_test_data = test_dataset[:, 0]\n",
    "X_test_data = tfidfconverter.transform(preprocessing(X_test_data)).toarray()\n",
    "print(len(X_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10001\n",
      "[False False False ... False False False]\n"
     ]
    }
   ],
   "source": [
    "# predict for new dataset\n",
    "y_pred = predict(classifier, X_test_data)\n",
    "print(len(y_pred))\n",
    "label_pred = inverse_transform(encoder, y_pred)\n",
    "print(label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the dataframe into csv file\n",
    "test_dataframe['label'] = label_pred\n",
    "test_dataframe.to_csv(\"test_data_10000_1_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=0)\n",
    "model=log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "y_pred = predict(log_reg, X_test)\n",
    "print(y_pred)\n",
    "label_pred =inverse_transform(encoder, y_pred)\n",
    "print(label_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "ml_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
